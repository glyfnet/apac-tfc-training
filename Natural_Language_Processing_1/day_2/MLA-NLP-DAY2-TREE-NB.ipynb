{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Based Models for a Regression Problem, and Hyperparameter Tuning\n",
    "\n",
    "We continue to work with our review dataset to see how Tree-based regressors (Decision Tree, Random Forest), along with efficient optimization techniques (GridSearch, RandomizedSearch), perform to predict the __log_votes__ field of our review dataset (that is very similar to the final project dataset).\n",
    "\n",
    "1. Reading the dataset\n",
    "2. Exploratory data analysis and missing value imputation\n",
    "3. Stop word removal and stemming\n",
    "4. Scaling numerical fields\n",
    "5. Splitting the training dataset into training and validation\n",
    "6. Computing Bag of Words features\n",
    "7. Fitting tree-based regressors and checking the validation performance\n",
    "    * Find more details on the __DecisionTreeRegressor__ here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "    * Find more details on the __RandomForestRegressor__ here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "8. Hyperparameter Tuning\n",
    "    * Find more details on the __GridSearchCV__ here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "    * Find more details on the __RandomizedSearchCV__ here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "9. Ideas for improvement\n",
    "\n",
    "Overall dataset schema:\n",
    "* __reviewText:__ Text of the review\n",
    "* __summary:__ Summary of the review\n",
    "* __verified:__ Whether the purchase was verified (True or False)\n",
    "* __time:__ UNIX timestamp for the review\n",
    "* __rating:__ Rating of the review\n",
    "* __log_votes:__ Logarithm-adjusted votes log(1+votes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading the dataset\n",
    "\n",
    "We will use the __pandas__ library to read our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/examples/NLP-REVIEW-DATA-REGRESSION.csv')\n",
    "\n",
    "print('The shape of the dataset is:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 10 rows of the dataset. As we can see the __log_votes__ field is numeric, so we build a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory data analysis and missing values imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the range and distribution of log_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_votes\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_votes\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"log_votes\"].plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of missing values for each columm below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill-in the missing values for __reviewText__ below. We will just use the placeholder \"Missing\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reviewText\"].fillna(\"Missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stop word removal and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library and functions\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the stop word removal and text cleaning processes below. NLTK library provides a list of common stop words. We will use the list, but remove some of the words from that list (because those words are actually useful to understand the sentiment in the sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Let's get a list of stop words from the NLTK library\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# These words are important for our problem. We don't want to remove them.\n",
    "excluding = ['against', 'not', 'don', \"don't\",'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
    "             'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", \n",
    "             'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n",
    "             'needn', \"needn't\",'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
    "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# New stop word list\n",
    "stop_words = [word for word in stop if word not in excluding]\n",
    "\n",
    "snow = SnowballStemmer('english')\n",
    "\n",
    "def process_text(texts): \n",
    "    final_text_list=[]\n",
    "    for sent in texts:\n",
    "        filtered_sentence=[]\n",
    "        \n",
    "        sent = sent.lower() # Lowercase \n",
    "        sent = sent.strip() # Remove leading/trailing whitespace\n",
    "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
    "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
    "        \n",
    "        for w in word_tokenize(sent):\n",
    "            # We are applying some custom filtering here, feel free to try different things\n",
    "            # Check if it is not numeric and its length>2 and not in stop words\n",
    "            if(not w.isnumeric()) and (len(w)>2) and (w not in stop_words):  \n",
    "                # Stem and add to filtered list\n",
    "                filtered_sentence.append(snow.stem(w))\n",
    "        final_string = \" \".join(filtered_sentence) #final string of cleaned words\n",
    " \n",
    "        final_text_list.append(final_string)\n",
    "    \n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pre-processing the reviewText field\")\n",
    "df[\"reviewText\"] = process_text(df[\"reviewText\"].tolist()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scaling numerical fields:\n",
    "\n",
    "We will apply min-max scaling to our rating field so that they will be between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rating\"] = (df[\"rating\"] - df[\"rating\"].min())/(df[\"rating\"].max()-df[\"rating\"].min())\n",
    "df[\"time\"] = (df[\"time\"] - df[\"time\"].min())/(df[\"time\"].max()-df[\"time\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Splitting the training dataset into training and validation\n",
    "\n",
    "Sklearn library has a useful function to split datasets. We will use the __train_test_split()__ function. In the example below, we get 90% of the data for training and 10% is left for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input: \"reviewText\", \"rating\" and \"time\"\n",
    "# Target: \"log_votes\"\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[[\"reviewText\", \"rating\", \"time\"]],\n",
    "                                                  df[\"log_votes\"].tolist(),\n",
    "                                                  test_size=0.10,\n",
    "                                                  shuffle=True\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Computing Bag of Words Features\n",
    "\n",
    "We are using binary features here. TF and TF-IDF are other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Initialize the binary count vectorizer\n",
    "tfidf_vectorizer = CountVectorizer(binary=True,\n",
    "                                   max_features=50 # Limit the vocabulary size\n",
    "                                  )\n",
    "# Fit and transform\n",
    "X_train_text_vectors = tfidf_vectorizer.fit_transform(X_train[\"reviewText\"].tolist())\n",
    "# Only transform\n",
    "X_val_text_vectors = tfidf_vectorizer.transform(X_val[\"reviewText\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print our vocabulary below. The number next to the word is its index in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge our features to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train_features = np.column_stack((X_train_text_vectors.toarray(), \n",
    "                                    X_train[\"rating\"].values, \n",
    "                                    X_train[\"time\"].values))\n",
    "X_val_features = np.column_stack((X_val_text_vectors.toarray(), \n",
    "                                  X_val[\"rating\"].values,\n",
    "                                  X_val[\"time\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Fitting tree-based regressors and checking the validation performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1  DecisionTreeRegressor\n",
    "Let's first fit a __DecisionTreeRegressor__ from Sklearn library, and check the performance on the validation dataset.\n",
    "\n",
    "Find more details on the __DecisionTreeRegressor__ here:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "dtRegressor = DecisionTreeRegressor(max_depth = 10,\n",
    "                                    min_samples_leaf = 15)\n",
    "dtRegressor.fit(X_train_features, y_train)\n",
    "dtRegressor_val_predictions = dtRegressor.predict(X_val_features)\n",
    "print(\"DecisionTreeRegressor on Validation: Mean_squared_error: %f, R_square_score: %f\" % \\\n",
    "      (mean_squared_error(y_val, dtRegressor_val_predictions), r2_score(y_val, dtRegressor_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2  RandomForestRegressor\n",
    "Let's now fit a __RandomForestRegressor__ from Sklearn library, and check the performance on the validation dataset.\n",
    "\n",
    "Find more details on the __RandomForestRegressor__ here:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "__Warning__: When experimenting with different sizes of random forests, keep in mind that random forest training can take a longer time to complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "rfRegressor = RandomForestRegressor(n_estimators = 200,\n",
    "                                    max_depth = 10,\n",
    "                                    min_samples_leaf = 15)\n",
    "rfRegressor.fit(X_train_features, y_train)\n",
    "rfRegressor_val_predictions =rfRegressor.predict(X_val_features)\n",
    "print(\"RandomForestRegressor on Validation: Mean_squared_error: %f, R_square_score: %f\" % \\\n",
    "      (mean_squared_error(y_val, rfRegressor_val_predictions), r2_score(y_val, rfRegressor_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Hyperparameter Tuning\n",
    "\n",
    "Let's try different parameter values and see how the __DecisionTreeRegressor__ model performs under some combinations of parameters.\n",
    "\n",
    "__Warning__: The number of hyperparameters tuned, along with the cross-validations, can greatly increase training time! Especially if trying hyperparameters tuning on the __RandomForestRegressor__ instead of the lower performing __DecisionTreeRegressor__ that we showcase below for speed! Similar tuning on a __RandomForestRegressor__ model can take more minutes to hours!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 GridSearchCV\n",
    "\n",
    "Find more details on the __GridSearchCV__ here:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "parameters = {'max_depth': [10, 20, 30, 40],\n",
    "              'min_samples_leaf': [5, 15, 25, 35]}\n",
    "                     \n",
    "# NOTE: GridSearchCV uses by default the score function of the estimator to evaluate \n",
    "# (r2_score for regression; accuracy_score for classification). If desired, \n",
    "# other scoring functions can be specified via the 'scoring' parameter. \n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "# NOTE: You can experiment with different cv numbers, default = 5\n",
    "regressor_grid = GridSearchCV(dt,\n",
    "                              parameters,\n",
    "                              cv=5,\n",
    "                              verbose=1,\n",
    "                              n_jobs=-1,\n",
    "                              scoring = 'neg_mean_squared_error')\n",
    "regressor_grid.fit(X_train_features, y_train)\n",
    "\n",
    "print(\"Best parameters: \", regressor_grid.best_params_)\n",
    "print(\"Best score: \", regressor_grid.best_score_)\n",
    "\n",
    "regressor_grid_val_predictions = regressor_grid.best_estimator_.predict(X_val_features)\n",
    "\n",
    "print(\"DecisionTreeRegressor with GridSearchCV on Validation: Mean_squared_error: %f, R_square_score: %f\" % \\\n",
    "      (mean_squared_error(y_val, regressor_grid_val_predictions), r2_score(y_val, regressor_grid_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 RandomizedSearchCV\n",
    "\n",
    "Find more details on the __RandomizedSearchCV__ here:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "  \n",
    "dt = DecisionTreeRegressor()\n",
    "parameters = {'max_depth': [10, 20, 30, 40],\n",
    "              'min_samples_leaf': [5, 15, 25, 35]}\n",
    "                      \n",
    "# NOTE: RandomizedSearchCV uses by default the score function of the estimator to evaluate\n",
    "# (r2_score for regression; accuracy_score for classification). \n",
    "# If desired, other scoring functions can be specified via the 'scoring' parameter.\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "# NOTE: You can experiment with different cv numbers, default = 5\n",
    "# NOTE: You can also experiment with different n_iter \n",
    "# (number of parameter settings that are sampled by the RandomizedSearch), default = 10\n",
    "regressor_rand = RandomizedSearchCV(dt,\n",
    "                                    parameters,\n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=-1,\n",
    "                                    scoring = 'neg_mean_squared_error')\n",
    "regressor_rand.fit(X_train_features, y_train)\n",
    "\n",
    "print(\"Best parameters: \", regressor_rand.best_params_)\n",
    "print(\"Best score: \", regressor_rand.best_score_)\n",
    "\n",
    "regressor_rand_val_predictions = regressor_rand.best_estimator_.predict(X_val_features)\n",
    "\n",
    "print(\"DecisionTreeRegressor with RandomizedSearchCV on Validation: Mean_squared_error: %f, R_square_score: %f\" % \\\n",
    "      (mean_squared_error(y_val, regressor_rand_val_predictions), r2_score(y_val, regressor_rand_val_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Ideas for improvement\n",
    "\n",
    "**Preprocessing**: We can usually improve performance with some additional work. You can try the following:\n",
    "* Change the feature extractor to TF, TF-IDF. Also experiment with different vocabulary size.\n",
    "* Add the other text field __summary__ to the model and get bag of words features of it.\n",
    "* Come up with some other features such as having certain punctuations, all-capitalized words or some words that might be useful in this problem.\n",
    "\n",
    "**Hyperparameter Tuning**: Always a good idea to try other parameter ranges and/or combinations of parameters. If training time is a priority, try __RandomizedSearchCV__ instead of __GridSearchCV__, it's much faster and with almost as good results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
